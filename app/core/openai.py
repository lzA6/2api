"""
OpenAI API endpoints
"""

import time
import json
import asyncio
from datetime import datetime
from typing import List, Dict, Any
from fastapi import APIRouter, Header, HTTPException
from fastapi.responses import StreamingResponse
import httpx

from app.core.config import settings
from app.models.schemas import OpenAIRequest, Message, ModelsResponse, Model
from app.utils.helpers import debug_log
from app.core.zai_transformer import ZAITransformer, generate_uuid
from app.utils.sse_tool_handler import SSEToolHandler

router = APIRouter()

# å…¨å±€è½¬æ¢å™¨å®ä¾‹
transformer = ZAITransformer()


@router.get("/v1/models")
async def list_models():
    """List available models"""
    current_time = int(time.time())
    response = ModelsResponse(
        data=[
            Model(id=settings.PRIMARY_MODEL, created=current_time, owned_by="z.ai"),
            Model(id=settings.THINKING_MODEL, created=current_time, owned_by="z.ai"),
            Model(id=settings.SEARCH_MODEL, created=current_time, owned_by="z.ai"),
            Model(id=settings.AIR_MODEL, created=current_time, owned_by="z.ai"),
            Model(id=settings.GLM_46_MODEL, created=current_time, owned_by="z.ai"),
            Model(id=settings.GLM_46_THINKING_MODEL, created=current_time, owned_by="z.ai"),
        ]
    )
    return response


@router.post("/v1/chat/completions")
async def chat_completions(request: OpenAIRequest, authorization: str = Header(...)):
    """Handle chat completion requests with ZAI transformer"""
    role = request.messages[0].role if request.messages else "unknown"
    debug_log(f"ğŸ˜¶â€ğŸŒ«ï¸ æ”¶åˆ° å®¢æˆ·ç«¯ è¯·æ±‚ - æ¨¡å‹: {request.model}, æµå¼: {request.stream}, æ¶ˆæ¯æ•°: {len(request.messages)}, è§’è‰²: {role}, å·¥å…·æ•°: {len(request.tools) if request.tools else 0}")
    
    try:
        # Validate API key (skip if SKIP_AUTH_TOKEN is enabled)
        if not settings.SKIP_AUTH_TOKEN:
            if not authorization.startswith("Bearer "):
                raise HTTPException(status_code=401, detail="Missing or invalid Authorization header")
            
            api_key = authorization[7:]
            if api_key != settings.AUTH_TOKEN:
                raise HTTPException(status_code=401, detail="Invalid API key")
            
        # ä½¿ç”¨æ–°çš„è½¬æ¢å™¨è½¬æ¢è¯·æ±‚
        request_dict = request.model_dump()
        debug_log("ğŸ”„ å¼€å§‹è½¬æ¢è¯·æ±‚æ ¼å¼: OpenAI -> Z.AI")
        
        transformed = await transformer.transform_request_in(request_dict)

        # è°ƒç”¨ä¸Šæ¸¸API
        async def stream_response():
            """æµå¼å“åº”ç”Ÿæˆå™¨ï¼ˆåŒ…å«é‡è¯•æœºåˆ¶ï¼‰"""
            retry_count = 0
            last_error = None
            current_token = transformed.get("token", "")  # è·å–å½“å‰ä½¿ç”¨çš„token

            while retry_count <= settings.MAX_RETRIES:
                try:
                    # å¦‚æœæ˜¯é‡è¯•ï¼Œé‡æ–°è·å–ä»¤ç‰Œå¹¶æ›´æ–°è¯·æ±‚
                    if retry_count > 0:
                        delay = 2.0
                        debug_log(f"é‡è¯•è¯·æ±‚ ({retry_count}/{settings.MAX_RETRIES}) - ç­‰å¾… {delay:.1f}s")
                        await asyncio.sleep(delay)

                        # æ ‡è®°å‰ä¸€ä¸ªtokenå¤±è´¥
                        if current_token:
                            transformer.mark_token_failure(current_token, Exception(f"Retry {retry_count}: {last_error}"))

                        # é‡æ–°è·å–ä»¤ç‰Œ
                        debug_log("ğŸ”‘ é‡æ–°è·å–ä»¤ç‰Œç”¨äºé‡è¯•...")
                        new_token = await transformer.get_token()
                        if not new_token:
                            debug_log("âŒ é‡è¯•æ—¶æ— æ³•è·å–æœ‰æ•ˆçš„è®¤è¯ä»¤ç‰Œ")
                            raise Exception("é‡è¯•æ—¶æ— æ³•è·å–æœ‰æ•ˆçš„è®¤è¯ä»¤ç‰Œ")
                        transformed["config"]["headers"]["Authorization"] = f"Bearer {new_token}"
                        current_token = new_token

                    async with httpx.AsyncClient(timeout=60.0) as client:
                        # å‘é€è¯·æ±‚åˆ°ä¸Šæ¸¸
                        # debug_log(f"ğŸ¯ å‘é€è¯·æ±‚åˆ° Z.AI: {transformed['config']['url']}")
                        async with client.stream(
                            "POST",
                            transformed["config"]["url"],
                            json=transformed["body"],
                            headers=transformed["config"]["headers"],
                        ) as response:
                            # æ£€æŸ¥å“åº”çŠ¶æ€ç 
                            if response.status_code == 400:
                                # 400 é”™è¯¯ï¼Œè§¦å‘é‡è¯•
                                error_text = await response.aread()
                                error_msg = error_text.decode('utf-8', errors='ignore')
                                debug_log(f"âŒ ä¸Šæ¸¸è¿”å› 400 é”™è¯¯ (å°è¯• {retry_count + 1}/{settings.MAX_RETRIES + 1})")
                                debug_log(f"ä¸Šæ¸¸é”™è¯¯å“åº”: {error_msg}")

                                retry_count += 1
                                last_error = f"400 Bad Request: {error_msg}"

                                # å¦‚æœè¿˜æœ‰é‡è¯•æœºä¼šï¼Œç»§ç»­å¾ªç¯
                                if retry_count <= settings.MAX_RETRIES:
                                    continue
                                else:
                                    # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ŒæŠ›å‡ºé”™è¯¯
                                    debug_log(f"âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({settings.MAX_RETRIES})ï¼Œè¯·æ±‚å¤±è´¥")
                                    error_response = {
                                        "error": {
                                            "message": f"Request failed after {settings.MAX_RETRIES} retries: {last_error}",
                                            "type": "upstream_error",
                                            "code": 400
                                        }
                                    }
                                    yield f"data: {json.dumps(error_response)}\n\n"
                                    yield "data: [DONE]\n\n"
                                    return

                            elif response.status_code == 401:
                                # è®¤è¯é”™è¯¯ï¼Œå¯èƒ½éœ€è¦é‡æ–°è·å–token
                                debug_log(f"âŒ è®¤è¯å¤±è´¥ (401)ï¼Œæ ‡è®°tokenå¤±æ•ˆ")
                                if current_token:
                                    transformer.mark_token_failure(current_token, Exception("401 Unauthorized"))
                                
                                retry_count += 1
                                last_error = "401 Unauthorized - Token may be invalid"
                                
                                if retry_count <= settings.MAX_RETRIES:
                                    continue
                                else:
                                    error_response = {
                                        "error": {
                                            "message": "Authentication failed after retries",
                                            "type": "auth_error",
                                            "code": 401
                                        }
                                    }
                                    yield f"data: {json.dumps(error_response)}\n\n"
                                    yield "data: [DONE]\n\n"
                                    return
                            
                            elif response.status_code == 429:
                                # é€Ÿç‡é™åˆ¶ï¼Œå»¶é•¿ç­‰å¾…æ—¶é—´é‡è¯•
                                debug_log(f"âŒ é€Ÿç‡é™åˆ¶ (429)ï¼Œå°†å»¶é•¿ç­‰å¾…æ—¶é—´é‡è¯•")
                                retry_count += 1
                                last_error = "429 Rate Limited"
                                
                                if retry_count <= settings.MAX_RETRIES:
                                    continue
                                else:
                                    error_response = {
                                        "error": {
                                            "message": "Rate limit exceeded",
                                            "type": "rate_limit_error", 
                                            "code": 429
                                        }
                                    }
                                    yield f"data: {json.dumps(error_response)}\n\n"
                                    yield "data: [DONE]\n\n"
                                    return
                            
                            elif response.status_code != 200:
                                # å…¶ä»–é”™è¯¯ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦é‡è¯•
                                error_text = await response.aread()
                                error_msg = error_text.decode('utf-8', errors='ignore')
                                debug_log(f"âŒ ä¸Šæ¸¸è¿”å›é”™è¯¯: {response.status_code}, è¯¦æƒ…: {error_msg}")
                                
                                # æŸäº›é”™è¯¯å¯ä»¥é‡è¯•
                                retryable_codes = [502, 503, 504]
                                if response.status_code in retryable_codes and retry_count < settings.MAX_RETRIES:
                                    retry_count += 1
                                    last_error = f"{response.status_code}: {error_msg}"
                                    debug_log(f"âš ï¸ æœåŠ¡å™¨é”™è¯¯ {response.status_code}ï¼Œå‡†å¤‡é‡è¯•")
                                    continue
                                
                                # ä¸å¯é‡è¯•çš„é”™è¯¯æˆ–å·²è¾¾åˆ°é‡è¯•ä¸Šé™
                                error_response = {
                                    "error": {
                                        "message": f"Upstream error: {response.status_code}",
                                        "type": "upstream_error",
                                        "code": response.status_code,
                                        "details": error_msg[:500]  # é™åˆ¶é”™è¯¯è¯¦æƒ…é•¿åº¦
                                    }
                                }
                                yield f"data: {json.dumps(error_response)}\n\n"
                                yield "data: [DONE]\n\n"
                                return

                            # 200 æˆåŠŸï¼Œå¤„ç†å“åº”
                            debug_log(f"âœ… Z.AI å“åº”æˆåŠŸï¼Œå¼€å§‹å¤„ç† SSE æµ")
                            if retry_count > 0:
                                debug_log(f"âœ¨ ç¬¬ {retry_count} æ¬¡é‡è¯•æˆåŠŸ")

                            # æ ‡è®°tokenä½¿ç”¨æˆåŠŸ
                            if current_token:
                                transformer.mark_token_success(current_token)

                            # åˆå§‹åŒ–å·¥å…·å¤„ç†å™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
                            has_tools = transformed["body"].get("tools") is not None
                            has_mcp_servers = bool(transformed["body"].get("mcp_servers"))
                            tool_handler = None

                            # å¦‚æœæœ‰å·¥å…·å®šä¹‰æˆ–MCPæœåŠ¡å™¨ï¼Œéƒ½éœ€è¦å·¥å…·å¤„ç†å™¨
                            if has_tools or has_mcp_servers:
                                chat_id = transformed["body"]["chat_id"]
                                model = request.model
                                tool_handler = SSEToolHandler(chat_id, model)

                                if has_tools and has_mcp_servers:
                                    debug_log(f"ğŸ”§ åˆå§‹åŒ–å·¥å…·å¤„ç†å™¨: {len(transformed['body'].get('tools', []))} ä¸ªOpenAIå·¥å…· + {len(transformed['body'].get('mcp_servers', []))} ä¸ªMCPæœåŠ¡å™¨")
                                elif has_tools:
                                    debug_log(f"ğŸ”§ åˆå§‹åŒ–å·¥å…·å¤„ç†å™¨: {len(transformed['body'].get('tools', []))} ä¸ªOpenAIå·¥å…·")
                                elif has_mcp_servers:
                                    debug_log(f"ğŸ”§ åˆå§‹åŒ–å·¥å…·å¤„ç†å™¨: {len(transformed['body'].get('mcp_servers', []))} ä¸ªMCPæœåŠ¡å™¨")

                            # å¤„ç†çŠ¶æ€
                            has_thinking = False
                            thinking_signature = None
                            first_thinking_chunk = True

                            # å¤„ç†SSEæµ - ä¼˜åŒ–çš„bufferå¤„ç†
                            buffer = bytearray()
                            incomplete_line = ""
                            line_count = 0
                            chunk_count = 0
                            last_activity = time.time()
                            debug_log("ğŸ“¡ å¼€å§‹æ¥æ”¶ SSE æµæ•°æ®...")

                            async for chunk in response.aiter_bytes():
                                chunk_count += 1
                                last_activity = time.time()
                                
                                if not chunk:
                                    continue

                                # å°†æ–°æ•°æ®æ·»åŠ åˆ°buffer
                                buffer.extend(chunk)
                                
                                # å°è¯•è§£ç å¹¶å¤„ç†å®Œæ•´çš„è¡Œ
                                try:
                                    # è§£ç ä¸ºå­—ç¬¦ä¸²å¹¶å¤„ç†
                                    text_data = buffer.decode('utf-8')
                                    
                                    # åˆ†å‰²ä¸ºè¡Œ
                                    lines = text_data.split('\n')
                                    
                                    # æœ€åä¸€è¡Œå¯èƒ½ä¸å®Œæ•´ï¼Œä¿å­˜åˆ°incomplete_line
                                    if not text_data.endswith('\n'):
                                        incomplete_line = lines[-1]
                                        lines = lines[:-1]
                                    else:
                                        # å¦‚æœæœ‰æœªå®Œæˆçš„è¡Œï¼Œå°†å…¶ä¸ç¬¬ä¸€è¡Œåˆå¹¶
                                        if incomplete_line:
                                            lines[0] = incomplete_line + lines[0]
                                            incomplete_line = ""
                                    
                                    # æ¸…ç©ºbufferï¼Œå¼€å§‹å¤„ç†æ–°çš„æ•°æ®
                                    buffer = bytearray()
                                    if incomplete_line:
                                        buffer.extend(incomplete_line.encode('utf-8'))
                                    
                                    # å¤„ç†å®Œæ•´çš„è¡Œ
                                    for current_line in lines:
                                        line_count += 1
                                        if not current_line.strip():
                                            continue

                                        if current_line.startswith("data:"):
                                            chunk_str = current_line[5:].strip()
                                            if not chunk_str or chunk_str == "[DONE]":
                                                if chunk_str == "[DONE]":
                                                    debug_log("ğŸ“¡ æ”¶åˆ° [DONE] ä¿¡å·")
                                                    yield "data: [DONE]\n\n"
                                                continue

                                            # debug_log(f"ğŸ“¦ è§£ææ•°æ®å—: {chunk_str[:200]}..." if len(chunk_str) > 200 else f"ğŸ“¦ è§£ææ•°æ®å—: {chunk_str}")

                                            try:
                                                chunk = json.loads(chunk_str)

                                                if chunk.get("type") == "chat:completion":
                                                    data = chunk.get("data", {})
                                                    phase = data.get("phase")

                                                    # è®°å½•æ¯ä¸ªé˜¶æ®µï¼ˆåªåœ¨é˜¶æ®µå˜åŒ–æ—¶è®°å½•ï¼‰
                                                    if phase and phase != getattr(stream_response, '_last_phase', None):
                                                        debug_log(f"ğŸ“ˆ SSE é˜¶æ®µ: {phase}")
                                                        stream_response._last_phase = phase

                                                    # å¤„ç†å·¥å…·è°ƒç”¨
                                                    if phase == "tool_call" and tool_handler:
                                                        for output in tool_handler.process_tool_call_phase(data, True):
                                                            yield output

                                                    # å¤„ç†å…¶ä»–é˜¶æ®µï¼ˆå·¥å…·ç»“æŸï¼‰
                                                    elif phase == "other" and tool_handler:
                                                        for output in tool_handler.process_other_phase(data, True):
                                                            yield output

                                                    # å¤„ç†æ€è€ƒå†…å®¹
                                                    elif phase == "thinking":
                                                        if not has_thinking:
                                                            has_thinking = True
                                                            # å‘é€åˆå§‹è§’è‰²
                                                            role_chunk = {
                                                                "choices": [
                                                                    {
                                                                        "delta": {"role": "assistant"},
                                                                        "finish_reason": None,
                                                                        "index": 0,
                                                                        "logprobs": None,
                                                                    }
                                                                ],
                                                                "created": int(time.time()),
                                                                "id": transformed["body"]["chat_id"],
                                                                "model": request.model,
                                                                "object": "chat.completion.chunk",
                                                                "system_fingerprint": "fp_zai_001",
                                                            }
                                                            yield f"data: {json.dumps(role_chunk)}\n\n"

                                                        delta_content = data.get("delta_content", "")
                                                        if delta_content:
                                                            # å¤„ç†æ€è€ƒå†…å®¹æ ¼å¼
                                                            if delta_content.startswith("<details"):
                                                                content = (
                                                                    delta_content.split("</summary>\n>")[-1].strip()
                                                                    if "</summary>\n>" in delta_content
                                                                    else delta_content
                                                                )
                                                            else:
                                                                content = delta_content
                                                            
                                                            # ç¬¬ä¸€ä¸ªæ€è€ƒå—æ·»åŠ <think>å¼€å§‹æ ‡ç­¾ï¼Œå…¶ä»–å—ä¿æŒçº¯å†…å®¹
                                                            if first_thinking_chunk:
                                                                formatted_content = f"<think>{content}"
                                                                first_thinking_chunk = False
                                                            else:
                                                                formatted_content = content

                                                            thinking_chunk = {
                                                                "choices": [
                                                                    {
                                                                        "delta": {
                                                                            "role": "assistant",
                                                                            "content": formatted_content,
                                                                        },
                                                                        "finish_reason": None,
                                                                        "index": 0,
                                                                        "logprobs": None,
                                                                    }
                                                                ],
                                                                "created": int(time.time()),
                                                                "id": transformed["body"]["chat_id"],
                                                                "model": request.model,
                                                                "object": "chat.completion.chunk",
                                                                "system_fingerprint": "fp_zai_001",
                                                            }
                                                            yield f"data: {json.dumps(thinking_chunk)}\n\n"

                                                    # å¤„ç†ç­”æ¡ˆå†…å®¹
                                                    elif phase == "answer":
                                                        edit_content = data.get("edit_content", "")
                                                        delta_content = data.get("delta_content", "")

                                                        # å¦‚æœè¿˜æ²¡æœ‰å‘é€è§’è‰²ï¼Œå…ˆå‘é€è§’è‰²chunk
                                                        if not has_thinking:
                                                            has_thinking = True  # è®¾ç½®æ ‡å¿—é¿å…é‡å¤å‘é€
                                                            role_chunk = {
                                                                "choices": [
                                                                    {
                                                                        "delta": {"role": "assistant"},
                                                                        "finish_reason": None,
                                                                        "index": 0,
                                                                        "logprobs": None,
                                                                    }
                                                                ],
                                                                "created": int(time.time()),
                                                                "id": transformed["body"]["chat_id"],
                                                                "model": request.model,
                                                                "object": "chat.completion.chunk",
                                                                "system_fingerprint": "fp_zai_001",
                                                            }
                                                            debug_log("â¡ï¸ å‘é€åˆå§‹è§’è‰²chunk")
                                                            yield f"data: {json.dumps(role_chunk)}\n\n"

                                                        # å¤„ç†æ€è€ƒç»“æŸå’Œç­”æ¡ˆå¼€å§‹
                                                        if edit_content and "</details>\n" in edit_content:
                                                            if has_thinking and not first_thinking_chunk:
                                                                # å‘é€æ€è€ƒç»“æŸæ ‡è®°</think>
                                                                thinking_signature = str(int(time.time() * 1000))
                                                                sig_chunk = {
                                                                    "choices": [
                                                                        {
                                                                            "delta": {
                                                                                "role": "assistant",
                                                                                "content": "</think>",
                                                                            },
                                                                            "finish_reason": None,
                                                                            "index": 0,
                                                                            "logprobs": None,
                                                                        }
                                                                    ],
                                                                    "created": int(time.time()),
                                                                    "id": transformed["body"]["chat_id"],
                                                                    "model": request.model,
                                                                    "object": "chat.completion.chunk",
                                                                    "system_fingerprint": "fp_zai_001",
                                                                }
                                                                yield f"data: {json.dumps(sig_chunk)}\n\n"

                                                            # æå–ç­”æ¡ˆå†…å®¹
                                                            content_after = edit_content.split("</details>\n")[-1]
                                                            if content_after:
                                                                content_chunk = {
                                                                "choices": [
                                                                    {
                                                                        "delta": {
                                                                            "role": "assistant",
                                                                            "content": content_after,
                                                                        },
                                                                        "finish_reason": None,
                                                                        "index": 0,
                                                                        "logprobs": None,
                                                                    }
                                                                ],
                                                                "created": int(time.time()),
                                                                "id": transformed["body"]["chat_id"],
                                                                "model": request.model,
                                                                "object": "chat.completion.chunk",
                                                                "system_fingerprint": "fp_zai_001",
                                                            }
                                                            yield f"data: {json.dumps(content_chunk)}\n\n"

                                                        # å¤„ç†å¢é‡å†…å®¹
                                                        elif delta_content:
                                                            # å¦‚æœè¿˜æ²¡æœ‰å‘é€è§’è‰²
                                                            if not has_thinking:
                                                                has_thinking = True  # é¿å…é‡å¤å‘é€
                                                                role_chunk = {
                                                                    "choices": [
                                                                        {
                                                                            "delta": {"role": "assistant"},
                                                                            "finish_reason": None,
                                                                            "index": 0,
                                                                            "logprobs": None,
                                                                        }
                                                                    ],
                                                                    "created": int(time.time()),
                                                                    "id": transformed["body"]["chat_id"],
                                                                    "model": request.model,
                                                                    "object": "chat.completion.chunk",
                                                                    "system_fingerprint": "fp_zai_001",
                                                                }
                                                                debug_log("â¡ï¸ å‘é€åˆå§‹è§’è‰²chunk")
                                                                yield f"data: {json.dumps(role_chunk)}\n\n"

                                                            content_chunk = {
                                                                "choices": [
                                                                    {
                                                                        "delta": {
                                                                            "content": delta_content,
                                                                        },
                                                                        "finish_reason": None,
                                                                        "index": 0,
                                                                        "logprobs": None,
                                                                    }
                                                                ],
                                                                "created": int(time.time()),
                                                                "id": transformed["body"]["chat_id"],
                                                                "model": request.model,
                                                                "object": "chat.completion.chunk",
                                                                "system_fingerprint": "fp_zai_001",
                                                            }
                                                            output_data = f"data: {json.dumps(content_chunk)}\n\n"
                                                            # debug_log(f"â¡ï¸ è¾“å‡ºå†…å®¹å—åˆ°å®¢æˆ·ç«¯: {delta_content[:50]}...")
                                                            yield output_data

                                                    # å¤„ç†å®Œæˆ - å½“æ”¶åˆ°usageä¿¡æ¯æ—¶
                                                    if data.get("usage"):
                                                        debug_log(f"ğŸ“¦ å®Œæˆå“åº” - ä½¿ç”¨ç»Ÿè®¡: {json.dumps(data['usage'])}")

                                                        # åªæœ‰åœ¨éå·¥å…·è°ƒç”¨æ¨¡å¼ä¸‹æ‰å‘é€æ™®é€šå®Œæˆä¿¡å·
                                                        if not tool_handler or not tool_handler.has_tool_call:
                                                            finish_chunk = {
                                                                "choices": [
                                                                    {
                                                                        "delta": {},  # ç©ºçš„deltaè¡¨ç¤ºç»“æŸ
                                                                        "finish_reason": "stop",
                                                                        "index": 0,
                                                                        "logprobs": None,
                                                                    }
                                                                ],
                                                                "usage": data["usage"],
                                                                "created": int(time.time()),
                                                                "id": transformed["body"]["chat_id"],
                                                                "model": request.model,
                                                                "object": "chat.completion.chunk",
                                                                "system_fingerprint": "fp_zai_001",
                                                            }
                                                            finish_output = f"data: {json.dumps(finish_chunk)}\n\n"
                                                            debug_log("â¡ï¸ å‘é€å®Œæˆä¿¡å·")
                                                            yield finish_output
                                                            debug_log("â¡ï¸ å‘é€ [DONE]")
                                                            yield "data: [DONE]\n\n"

                                            except json.JSONDecodeError as e:
                                                debug_log(f"âŒ JSONè§£æé”™è¯¯: {e}, å†…å®¹: {chunk_str[:200]}")
                                            except Exception as e:
                                                debug_log(f"âŒ å¤„ç†chunké”™è¯¯: {e}")
                                
                                except UnicodeDecodeError:
                                    # å¦‚æœè§£ç å¤±è´¥ï¼Œå¯èƒ½æ˜¯æ•°æ®ä¸å®Œæ•´ï¼Œç»§ç»­æ¥æ”¶
                                    debug_log(f"âš ï¸ æ•°æ®è§£ç å¤±è´¥ï¼Œç¼“å†²åŒºå¤§å°: {len(buffer)}")
                                    if len(buffer) > 1024 * 1024:  # 1MBé™åˆ¶
                                        debug_log("âŒ ç¼“å†²åŒºè¿‡å¤§ï¼Œæ¸…ç©ºé‡è¯•")
                                        buffer = bytearray()
                                        incomplete_line = ""
                                except Exception as e:
                                    debug_log(f"âŒ Bufferå¤„ç†å¼‚å¸¸: {e}")
                                    # æ¸…ç©ºbufferç»§ç»­å¤„ç†
                                    buffer = bytearray()
                                    incomplete_line = ""
                                
                                # æ£€æŸ¥æ˜¯å¦é•¿æ—¶é—´æ²¡æœ‰æ´»åŠ¨ï¼ˆè¶…æ—¶æ£€æŸ¥ï¼‰
                                if time.time() - last_activity > 30:  # 30ç§’è¶…æ—¶
                                    debug_log("âš ï¸ æ£€æµ‹åˆ°é•¿æ—¶é—´æ— æ´»åŠ¨ï¼Œå¯èƒ½è¿æ¥ä¸­æ–­")
                                    break

                            # ç¡®ä¿å‘é€ç»“æŸä¿¡å·
                            if not tool_handler or not tool_handler.has_tool_call:
                                debug_log("ğŸ“¤ å‘é€æœ€ç»ˆ [DONE] ä¿¡å·")
                                yield "data: [DONE]\n\n"

                            debug_log(f"âœ… SSE æµå¤„ç†å®Œæˆï¼Œå…±å¤„ç† {line_count} è¡Œæ•°æ®ï¼Œ{chunk_count} ä¸ªæ•°æ®å—")
                            
                            # æ£€æŸ¥å¤„ç†å®Œæ•´æ€§
                            is_complete = True
                            completion_issues = []
                            
                            if line_count == 0:
                                is_complete = False
                                completion_issues.append("æ²¡æœ‰å¤„ç†ä»»ä½•æ•°æ®è¡Œ")
                            elif chunk_count == 0:
                                is_complete = False
                                completion_issues.append("æ²¡æœ‰æ”¶åˆ°ä»»ä½•æ•°æ®å—")
                            elif chunk_count > 0:
                                debug_log(f"ğŸ“Š å¹³å‡æ¯ä¸ªæ•°æ®å—åŒ…å« {line_count/chunk_count:.1f} è¡Œ")
                            
                            # æ£€æŸ¥å·¥å…·è°ƒç”¨å®Œæ•´æ€§
                            if tool_handler and tool_handler.has_tool_call:
                                if not tool_handler.completed_tools:
                                    completion_issues.append("å·¥å…·è°ƒç”¨æœªæ­£å¸¸å®Œæˆ")
                                else:
                                    debug_log(f"âœ… å·¥å…·è°ƒç”¨å®Œæˆ: {len(tool_handler.completed_tools)} ä¸ªå·¥å…·")
                            
                            # æ£€æŸ¥æ€è€ƒå†…å®¹å®Œæ•´æ€§ï¼ˆåªæœ‰çœŸæ­£çš„thinkingæ¨¡å¼æ‰éœ€è¦ç­¾åï¼‰
                            # æ³¨æ„ï¼šæ™®é€šçš„answeré˜¶æ®µä¸éœ€è¦thinkingç­¾åï¼Œåªæœ‰thinkingé˜¶æ®µæ‰éœ€è¦
                            # if has_thinking and not thinking_signature:
                            #     completion_issues.append("æ€è€ƒå†…å®¹ç¼ºå°‘ç­¾å")
                            
                            # æŠ¥å‘Šå®Œæ•´æ€§çŠ¶æ€
                            if is_complete and not completion_issues:
                                debug_log("âœ… å“åº”å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡")
                            else:
                                debug_log(f"âš ï¸ å“åº”å®Œæ•´æ€§é—®é¢˜: {', '.join(completion_issues)}")
                                
                                # å¦‚æœé—®é¢˜ä¸¥é‡ä¸”è¿˜æœ‰é‡è¯•æœºä¼šï¼Œè€ƒè™‘é‡è¯•
                                critical_issues = ["æ²¡æœ‰å¤„ç†ä»»ä½•æ•°æ®è¡Œ", "æ²¡æœ‰æ”¶åˆ°ä»»ä½•æ•°æ®å—"]
                                has_critical_issue = any(issue in completion_issues for issue in critical_issues)
                                
                                if has_critical_issue and retry_count < settings.MAX_RETRIES:
                                    debug_log("ğŸ”„ æ£€æµ‹åˆ°ä¸¥é‡å®Œæ•´æ€§é—®é¢˜ï¼Œå‡†å¤‡é‡è¯•")
                                    retry_count += 1
                                    last_error = f"Incomplete response: {', '.join(completion_issues)}"
                                    continue
                            
                            # æˆåŠŸå¤„ç†å®Œæˆï¼Œé€€å‡ºé‡è¯•å¾ªç¯
                            return

                except Exception as e:
                    debug_log(f"âŒ æµå¤„ç†é”™è¯¯: {e}")
                    import traceback
                    debug_log(traceback.format_exc())

                    # æ ‡è®°tokenå¤±è´¥
                    if current_token:
                        transformer.mark_token_failure(current_token, e)

                    # æ£€æŸ¥æ˜¯å¦è¿˜å¯ä»¥é‡è¯•
                    retry_count += 1
                    last_error = str(e)

                    if retry_count > settings.MAX_RETRIES:
                        # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè¿”å›é”™è¯¯
                        debug_log(f"âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({settings.MAX_RETRIES})ï¼Œæµå¤„ç†å¤±è´¥")
                        error_response = {
                            "error": {
                                "message": f"Stream processing failed after {settings.MAX_RETRIES} retries: {last_error}",
                                "type": "stream_error"
                            }
                        }
                        yield f"data: {json.dumps(error_response)}\n\n"
                        yield "data: [DONE]\n\n"
                        return

        # è¿”å›æµå¼å“åº”
        debug_log("ğŸš€ å¯åŠ¨ SSE æµå¼å“åº”")
        
        # åˆ›å»ºä¸€ä¸ªåŒ…è£…çš„ç”Ÿæˆå™¨æ¥è¿½è¸ªæ•°æ®æµ
        async def logged_stream():
            chunk_count = 0
            try:
                debug_log("ğŸ“¤ å¼€å§‹å‘å®¢æˆ·ç«¯æµå¼ä¼ è¾“æ•°æ®...")
                async for chunk in stream_response():
                    chunk_count += 1
                    # debug_log(f"ğŸ“¤ å‘é€å—[{chunk_count}]: {chunk[:200]}..." if len(chunk) > 200 else f"  ğŸ“¤ å‘é€å—[{chunk_count}]: {chunk}")
                    yield chunk
                debug_log(f"âœ… æµå¼ä¼ è¾“å®Œæˆï¼Œå…±å‘é€ {chunk_count} ä¸ªæ•°æ®å—")
            except Exception as e:
                debug_log(f"âŒ æµå¼ä¼ è¾“ä¸­æ–­: {e}")
                raise
        
        return StreamingResponse(
            logged_stream(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
            },
        )

    except HTTPException:
        raise
    except Exception as e:
        debug_log(f"âŒ å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback

        debug_log(f"âŒ é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")